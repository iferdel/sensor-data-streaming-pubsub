# Sensor Data Streaming PubSub

## General Description

![grafana-dashboard](./assets/grafana-dashboard.gif)
* (GIF showing grafana-dashboard with more than one sensor + monitor db queries --stats from postgres using timescaledb functionality--)
* (GIF showing iotctl behaviour -- maybe with bubbletea implemented already which would beautify the status of running sensors and not running sensors)*
* (GIF showing pods on k8 -- invitation to [homelab](https://github.com/iferdel/homelab))
* *maybe(GIF showing map with GPS data from sensors -- either static or dynamic locations)*

* General diagram (excalidraw or another software)

I think that a design like this is a good starting point for a larger project that would involve a real and broader sensor monitoring spectrum with GPS (either via Wi-Fi or GSM), in mobile vehicles or static machinery aswell as in civil infrastructure.

## Reason

Back in 2020, I worked on **vibration analysis**. My main background at that time was in **Mechanical Engineering**, and I took on a role that involved designing sensor installations, performing in-field measurements, and analyzing the data back at the office. 

I measured various types of mechanical equipment, such as overhead cranes in a mining plant and climate control systems (including pumps, cooling towers and air handling units) at Chile’s main airport. Additionally, I assessed civil structures--protected, commercial, and private buildings--subjected to nearby construction or physical phenomena, such as vibrations generated by passing trains.

All of these tasks were performed **in-situ**, which motivated me to consider a more ambitious approach: **remote, real-time monitoring**. Such a system could open up new business opportunities by offering continuous insight without requiring on-site personnel.

With that in mind, my goal for this project is to build a comprehensive **end-to-end**, real-time monitoring solution.


## :deciduous_tree: Directory Tree 
*I like the structure that became manifest while developing the project. That's why I'm attaching the filetree since it reads nicely.*
```
.
├── LICENSE
├── README.md
├── assets
│   └── grafana-dashboard.gif
├── cmd
│   ├── iotctl
│   │   ├── Dockerfile
│   │   ├── cmd
│   │   │   ├── awake.go
│   │   │   ├── changesamplefrequency.go
│   │   │   ├── delete.go
│   │   │   ├── root.go
│   │   │   ├── sensorstatus.go
│   │   │   └── sleep.go
│   │   └── main.go
│   ├── sensor-logs-ingester
│   │   ├── Dockerfile
│   │   ├── handlers.go
│   │   └── main.go
│   ├── sensor-measurements-ingester
│   │   ├── Dockerfile
│   │   ├── handlers.go
│   │   └── main.go
│   ├── sensor-registry
│   │   ├── Dockerfile
│   │   ├── handlers.go
│   │   └── main.go
│   └── sensor-simulation
│       ├── Dockerfile
│       ├── handlers.go
│       └── main.go
├── compose.yaml
├── dependencies
│   ├── grafana
│   │   ├── README.md
│   │   ├── grafana.ini
│   │   └── provisioning
│   │       ├── dashboards
│   │       │   ├── iot.json
│   │       │   ├── iot.yaml
│   │       │   └── queries.sql
│   │       └── datasources
│   │           └── datasources.yaml
│   ├── rabbitmq
│   │   ├── Dockerfile
│   │   ├── definitions.json
│   │   └── rabbitmq.conf
│   └── timescaledb
│       ├── Dockerfile
│       ├── init.sh
│       └── postgresql.conf
├── go.mod
├── go.sum
├── ideas.md
├── internal
│   ├── pubsub
│   │   ├── consume.go
│   │   └── publish.go
│   ├── routing
│   │   ├── models.go
│   │   └── routing.go
│   ├── sensorlogic
│   │   ├── awake.go
│   │   ├── changesamplefrequency.go
│   │   ├── sensor.go
│   │   ├── sensorlogs.go
│   │   ├── sensormeasurements.go
│   │   ├── sensorsignal.go
│   │   └── sleep.go
│   └── storage
│       ├── README.md
│       ├── db.go
│       ├── logs.go
│       ├── measurements.go
│       ├── models.go
│       └── sensors.go
└── utils
    └── wait-for-services.sh
```
## Architecture :rabbit: :elephant: :tiger: :whale: :octopus:

*(high-level system diagram to visualize the architecture)*
This solution is based on an **event-driven** architecture using a **pub/sub** pattern at its core, powered by a **distributed system**. The project is intended to be hosted on a **Kubernetes cluster** to ensure high availability and horizontal scaling as needed—for example, if sensor sampling rates increase or if we add more sensors.
The services in question are:
* sensor simulation
* sensor registry
* logs ingester
* measurement ingester
* control iotctl 

Besides this services, to a processing service that stores the data in a database, and finally to a dashboard for visualization.

### Key architectural points :seven::seven::seven::
*Disclaimer: Here we are considering an entire PubSub architecture, but one could conclude that a hybrid architecture for critical low-latency control would also be quite handy. In that case, one would expect using gRPC as the way to communicate between a service that would send direct commands to change behaviour (in a reactive way) not the sensor but to the machine or whatever is behind.*
- **Data Transfer**: The solution is intended to use Protobuf as a data serialization format to match real scenarios with embedded C or C++. However, for the initial setup (POC), the Go encoding/gob serializer will be used.
- **Infrastructure**: This project integrates with my [homelab](https://github.com/iferdel/homelab), which simulates a cloud-like environment on bare metal using TalosOS and GitOps with FluxCD.
- **CI/CD**: For CI/CD, I’m using a private Jenkins server and Docker Hub for image storage, while the GitHub repository hosts the source code. The whole CD would be handled with FluxCD.
- **Secrets**: I’m using Azure Key Vault for secrets in the homelab. 
- **Database**: The solution uses PostgreSQL with [TimeScaleDB](https://www.timescale.com/), an extension optimized for time-series data. In a real scenario, the paid cloud tier would be in use, but for this project I’m storaging everything on bare metal, integrated with CloudNativePG and OpenEBS + Mayastor for storage. Ephemeral and with data retention policy.
- **Data Management**: TimeScaleDB’s policies handle data expiration and compression, preventing storage overflow and improving performance.
- **Visualization**: Grafana is used for near real-time dashboards, leveraging its querying capabilities to visualize time-series data stored as well as stats from the database itself by means of wrapping the stats from pg_stat_statements and pg_stat_kcache with postgres CTEs and procedures.
- **Alarms**: *...*  
- **Communication Protocols**:
    - *Sensor communication uses MQTT with streaming queues.*
    - *Inter-service communication uses AMQP with RabbitMQ, employing quorum queues.*
    - *Alarm service communication uses gRPC for low-latency communication with the machine where the sensor to affect behaviour*

## Design :art:
'paint on a canvas' - kawhi leonard

Sensors will send:
    - id (serial number)
    - timestamp (with nanosecond precision)
    - measurement (at a variable sample frequency)
    - GPS location (latitude and longitude)
This approach allows flexible scaling of the number of sensors and their data rates.

Sensor will receive (mapped through its id):
    - commands that would affect the sensor behaviour such as sleep, awake and change sample frequency.

## Database Schemas :floppy_disk:

(image of ERD)

## Monitoring :computer:

TimeScaleDB integrates seamlessly with Grafana, allowing real-time querying and visualization of sensor data. This enables quick insights into sensor performance, trends, and anomalies.

## Examples :cherries:

(tmux showing up logs and cmd applying behavioural changes over the sensors.)
(...)

## Thoughts on the Process...

### Simulation

I'm thinking of simulating tens, hundreds and why not, thousands of sensors sending data.
So not only the pubsub is being tested with this high throughput of data, but the database.

### Microservices Considered

In addition to the sensor layer (client), three key microservices will form the core of this architecture:
    Sensor Control Panel: A service (or CLI tool) that interacts with each sensor to adjust operational parameters, such as putting a sensor to sleep or changing its sampling frequency.
    Sensor Data Capture: A horizontally scalable service (utilizing Kubernetes Horizontal Pod Autoscaling) that consumes sensor data and writes it to the database.
    Sensor Data Processing & Alarms: A service that analyzes incoming data to detect patterns or threshold violations and then triggers commands or alarms as needed.

### Pub Sub Compontents to be Used

Exchange, Queues, and Routing Keys:

    Exchange: sensor_streaming
    Queues: sensor_{i} for each sensor i
    Routing Keys:
        sensor_{i}.commands.sleep
        sensor_{i}.commands.change_sample_frequency
        sensor_{i}.data
        sensor_{i}.alarms.trigger

### Pub/Sub Pattern for Each Microservice:

1) Sensor:
    Publisher: Sensor data and acknowledgments after commands or triggers are processed
    Subscriber: Commands and alarms sent from other services
2) Sensor Control Panel:
    Publisher: Commands (with necessary arguments) sent to sensors
    Subscriber: Sensor status updates and command acknowledgments
3) Sensor Data Capture:
    Subscriber: Consumes continuous sensor data streams for persistence in the database
    Sensor Data Processing & Alarms:
        Publisher: Triggers or alerts based on analyzed sensor data
        Subscriber: Receives raw sensor data for processing

